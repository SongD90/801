---
title: "Code801"
author: "Marianne Huebner"
date: "August 21, 2016"
output: word_document
---

```{r, echo=FALSE}
setwd("~/Desktop/Teaching/801/Lectures/Rcode")

library(ggplot2)
library(ggthemes)
library(extrafont)
library(graphics)

library(car)

library(xtable)
```


*Most code is based on Christophe Lalanne's R Companion to Montgomery's Design and Analysis of Experiements (2005)*

## Probability distributions

For example, for the F distribution the R code format is \tt{df(x, df1, df2, log = FALSE)} where
\tt{df} gives the density, \tt{pf}  the distribution function, \tt{qf} is 
the quantile function, and \tt{rf} generates random deviates.
```{r, prob}

curve(dnorm(x,0,1), -3,3, ylab="normal density", col="blue")
curve(dnorm(x,1,1), -3,3, col="green", add=TRUE)
curve(dnorm(x,0,2), -3,3, col="red", add=TRUE)

#dt(x, df, ncp=0, log = FALSE)
#pt(q, df, ncp=0, lower.tail = TRUE, log.p = FALSE)
#qt(p, df,        lower.tail = TRUE, log.p = FALSE)
#rt(n, df)

curve(dt(x,10), -3,3, ylab="t density", col="green")
curve(dt(x,1), -3,3, col="blue", add=TRUE)
 legend(1,.35, c("df=10", "df=1"),col=c("green","blue"), lty=1)

#dchisq(x, df, ncp=0, log = FALSE)
curve(dchisq(x,2), 0,30, lty=1, ylab="chisquare density", col="green")
curve(dchisq(x,5),  lty=2, col="blue", add=TRUE)
curve(dchisq(x,10),  lty=3, col="red", add=TRUE)
legend(20,.5, c("df=2","df=5","df=10"),cex=1, col=c("green","blue", "red"), lty=1:3)
```



## Chapter 2: Comparison of two groups


```{r, chap2tension}
set.seed(801)
# Tension Bond Strength data (Tab. 2-1, p. 24)
y1 <- c(16.85,16.40,17.21,16.35,16.52,17.04,16.96,17.15,16.59,16.57)
y2 <- c(16.62,16.75,17.37,17.12,16.98,16.87,17.34,17.02,17.08,17.27)
y <- data.frame(Modified=y1,Unmodified=y2)
y.means <- as.numeric(apply(y,2,mean))
#opar <- par(mfrow=c(2,1),mar=c(5,7,4,2),las=1) 
stripchart(y,xlab=expression("Strength (kgf/cm^2)"),pch=19) 
arrows(y.means,rep(1.5,2),y.means,c(1.1,1.9),length=.1) 
text(y.means,c(1.2,1.8),round(y.means,2),pos=4,cex=.8)
# Random deviates (instead of data from metal recovery used in the book) 
rd <- rnorm(200,mean=70,sd=5)
hist(rd,xlab="quantile",nclass=200, ylab="Relative frequency",
main="Random Normal Deviates\n N(70,5)") 
#par(opar)


boxplot(y,ylab="Strength (kgf/cm^2)",las=1)
```

```{r chap2ttest}
t.test(y1,y2,var.equal=TRUE)
as.numeric(diff(apply(y,2,mean)))
t.test(y1,y2)

qqnorm(y1)
qqline(y1)

```


```{r chap2hardness}
tmp<-c(7,3,3,4,8,3,2,9,5,4,6,3,5,3,8,2,4,9,4,5)
hardness <- data.frame(y = tmp, tip = gl(2,10))
t.test(y ~ tip, data = hardness, paired = TRUE)

with(hardness, plot(y[tip==1],y[tip==2],xlab="Tip 1",ylab="Tip 2"))
  abline(0,1)
  with(hardness, plot(y[tip==1]+y[tip==2],y[tip==1]-y[tip==2],
                      xlab="Tip 1 + Tip 2",ylab="Tip 1 - Tip 2",ylim=c(-3,3)))
abline(h=0)

#ignoring pairing
t.test(y ~ tip, data = hardness, var.equal = TRUE)

#nonparametric
wilcox.test(y1,y2)
wilcox.test(y~tip,data=hardness,paired=TRUE)
```


## Chapter 3: ANOVA - Comparison of multiple groups


**Example**: Unwanted material on silion coated wafers is removed by an etching process. The fiure below visualizes the association of the radio-frequency (RF) power setting with the etch rate.

```{r etchrate}
etch.rate <- read.table("~/Desktop/Teaching/801/Lectures/Rcode/data/etchrate.txt",header=T)
grp.means <- with(etch.rate, tapply(rate,RF,mean))
with(etch.rate, stripchart(rate~RF,vert=T,method="overplot",pch=1, ylab=""));
stripchart(as.numeric(grp.means)~as.numeric(names(grp.means)),pch="x", cex=1.5,vert=T,add=T)
title(main="Etch Rate data",ylab=expression(paste("Observed Etch Rate (",ring(A),"/min)")),xlab="RF Power (W)");
legend("bottomright","Group Means",pch="x",bty="n")
```


Radio-frequency and run are factors in the ANOVA analysis.
```{r aov}
# first, we convert each variable to factor 
etch.rate$RF <- as.factor(etch.rate$RF)
etch.rate$run <- as.factor(etch.rate$run) 
# next, we run the model
etch.rate.aov <- aov(rate~RF,etch.rate) 
summary(etch.rate.aov)
```

```{r lambs}
diet1<-c(8,16,9)
diet2<-c(9,16,21,11,18)
diet3<-c(15,10,17,6)
lambs<-cbind(c(rep(1,3),rep(2,5),rep(3,4)),
+ c(diet1,diet2,diet3))
colnames(lambs)<-c("diet","wtgain")
lambs<-data.frame(lambs)

 lambs$diet<-factor(lambs$diet, labels=c(1,2,3))
 anova(lm(lambs$wtgain ~ factor(lambs$diet)))
```

Plots
```{r lampbsplots}
 stripchart(lambs$wtgain~lambs$diet, vert=T, pch=16)
#pdf(file="~/Desktop/Teaching/801/Lectures/Anova_Chap3/lambs_diagnostics.pdf")
par(mfrow=c(2,2))
plot(lm(lambs$wtgain ~ factor(lambs$diet)))
par(mfrow=c(1,1))
#dev.off()
```

```{r modelcheck}
par(mfrow=c(2,2), cex=0.8)
plot(etch.rate.aov)
par(mfrow=c(1,1))

# for a subset of predictors use individual plots
plot(fitted(etch.rate.aov), residuals(etch.rate.aov))  #residuals
qqnorm(residuals(etch.rate.aov)); qqline(residuals(etch.rate.aov))  #normal qq-plot   

durbinWatsonTest(etch.rate.aov)  #test for independence of residuals
bartlett.test(rate~RF,data=etch.rate)  #test for homoscedasticity (constant variance)
leveneTest(etch.rate.aov)   #test for homogeneity of variances

shapiro.test(etch.rate$rate[etch.rate$RF==160])  #normality in subgroups

shapiro.test(etch.rate$rate)  
```



**Power and sample size for ANOVA models**
```{r power}

grp.means <- c(575,600,650,675) 
power.anova.test(groups=4,between.var=var(grp.means),within.var=25^2,
sig.level=.01,power=.90)


#operating characteristic curve (OCC) = plot power against a parameter
# here a=4, 
# how does sd and sample size influence power?

sd <- seq(20,80,by=2)
nn <- seq(4,20,by=2)
beta <- matrix(NA,nr=length(sd),nc=length(nn))

for (i in 1:length(sd))
      beta[i,] <- power.anova.test(groups=4,n=nn,between.var=var(grp.means),
                  within.var=sd[i]^2,sig.level=.01)$power 

colnames(beta) <- nn; 
rownames(beta) <- sd

matplot(sd,beta,type="l",xlab=expression(sigma),ylab=expression(1-beta),col=1, lty=1)
  grid()
text(rep(80,10),beta[length(sd),],as.character(nn),pos=3) 
title("Operating Characteristic Curve\n for a=4 treatment means")
```

**Multiple Comparisons**

```{r comparison}
#comparison of treatment means
pairwise.t.test(etch.rate$rate,etch.rate$RF,p.adjust.method="bonferroni") 
pairwise.t.test(etch.rate$rate,etch.rate$RF,p.adjust.method="hochberg")

#taking into account inflation of type I error
TukeyHSD(etch.rate.aov) 
plot(TukeyHSD(etch.rate.aov),las=1)
```


Tensile strength and cotton weight percent (problem 3.10 and 3.11 Montogomery)
```{r cotton}
cotton<-c(15, 20,25,30,35,15,20,25,30,35,15,20,25,30,35,15,20,25,30,35,15,20,25,30,35)
tensile<-c(7,12,14,19,7,7,17,19,25,10,15,12,19,22,11,11,18,18,19,15,9,18,18,23,11)
cloth<-data.frame(cotton=factor(cotton), tensile=tensile)

# 1. calculate group means
cloth.means<-tapply(cloth$tensile, cloth$cotton, mean)
cloth.means

nn<-tapply(cloth$tensile, cloth$cotton, length)

# 2. ANOVA model
cloth.aov<-aov(tensile ~ cotton, cloth)
summary(cloth.aov, intercept=T)

# 3. Pairwise test of mean differences
pairwise.t.test(cloth$tensile, cloth$cotton, p.adjust="none", pool.sd=T)

# 4. Tukey test on all possible pairs
TukeyHSD(cloth.aov, conf.level=0.95)
plot(TukeyHSD(cloth.aov, conf.level=0.95))

# 5. Tukey method step-by-step
       # from ANOVA table
ntrt<-5        # number of treatments
dferror<-20    # N-a
mserror<-8.06  # MSE residuals
contrastcoef<-c(-1,0,0,1,0)  #contrast (30% cotton as control)
meandiff<-sum(contrastcoef*cloth.means); meandiff  #difference in means
sediff<-sqrt( (mserror/2)* sum( (1/nn)*abs(contrastcoef)) ); sediff #standard error of the difference

critq<-meandiff/sediff
qtukey(0.95, ntrt, dferror)  #studentized range distribution quantile
# 95% confidence interval for the contrast
lowci<-meandiff - qtukey(0.95, ntrt, dferror)*sediff
upci<-meandiff + qtukey(0.95, ntrt, dferror)*sediff
lowci;upci

# pvalue
ptukey(meandiff/sediff, ntrt, dferror, lower.tail=F)


# 6. Scheffe method step-by-step
       # from ANOVA table
ntrt<-5        # number of treatments
dfnum<- 4      # a-1
dferror<-20    # N-a
mserror<-8.06  # MSE residuals
contrastcoef<-c(-1,0,0,1,0)  #contrast (30% cotton as control)
meandiff<-sum(contrastcoef*cloth.means); meandiff  #estimated contrast
sscoef<-sum(contrastcoef*contrastcoef/nn) # sum of squared contrast coefficients

msdiff<-meandiff*meandiff/sscoef    # mean squared for contrast
Fcontrast<-msdiff/mserror; Fcontrast

critval <- dfnum* qf(0.05, dfnum, dferror, lower.tail=F)  #Scheffe F

lowci<-meandiff - sqrt(critval)*sqrt(mserror*sscoef)
upci<-meandiff + sqrt(critval)*sqrt(mserror*sscoef)
lowci; upci

# 7. Dunnett method step-by-step

ntrt<-5        # number of treatments
dfnum<- 4      # a-1
dferror<-20    # N-a
mserror<-8.06  # MSE residuals
contrastcoef<-c(-1,0,0,1,0)  #contrast (30% cotton as control)
meandiff<-sum(contrastcoef*cloth.means);   #difference in means
sediff<-sqrt( (mserror/ntrt)); 

# critical value
library(nCDunnett)
# qNCDun(0.95, nu=dferror, rho=(rep(0.5,times=dfnum)), delta=rep(0,times=dfnum), two.sided=F)

critval<-2.65

# 95% confidence interval for the contrast
lowci<-meandiff - critval*sediff
upci<-meandiff + critval*sediff
lowci;upci

```



## Chapter 4: RCBD - Randomized Complete Block Design

A product developer decides to investigate the effect of four different levels of extrusion pressure on flicks using a RCBD considering batches of resin as blocks.

```{r rcbd}
y<-c(90.3, 89.2, 98.2, 93.9, 87.4, 97.9,
92.5, 89.5, 90.6, 94.7, 87.0, 95.8,
85.5, 90.8, 89.6, 86.2, 88.0, 93.4,
82.5, 89.5, 85.6, 87.4, 78.9, 90.7)
psi.labels <- c(8500,8700,8900,9100)
vasc <- data.frame(psi=gl(4,6,24),batch=gl(6,1,24),y)

boxplot(y~psi, vasc)
boxplot(y~batch, vasc)

interaction.plot(vasc$psi, vasc$batch, vasc$y,  fun=mean, col=1:6, ylab="mean of y", xlab="PSI")

vasc.aov <- aov(y~batch+psi,vasc)
summary(vasc.aov)
```


Latin square design: Rocket propellant problem
```{r latin}
rocket<-data.frame(y=c(24, 20, 19, 24, 24, 17, 24, 30, 27, 36, 18, 38, 26, 27, 21, 26, 31, 26, 23, 22, 22, 30, 20, 29, 31), batch=rep(1:5, each=5), op=rep(1:5, 5),        
                   treat=c("A","B","C","D","E",  "B","C","D","E","A", "C", "D","E", "A", "B", "D","E", "A","B","C", "E", "A","B","C","D"))
 
plot(y~op+batch+treat,rocket)
rocket.lm <- lm(y~factor(op)+factor(batch)+treat,rocket) 
anova(rocket.lm)

```

BIB: Balanced incomplete block design

In a catalyst experiment the time of reaction for a chemical process is studied as a function of catalyst type administered to four different batches of raw material. These batches are considered as the blocking elements.

```{r bib}
y <- matrix(c(73,NA,73,75,74,75,75,NA,NA,67,68,72,71,72,NA,75),nc=4) 
chemproc <- data.frame(rep=as.vector(y),
treat=factor(rep(1:4,4)),
batch=factor(rep(1:4,each=4))) 

summary(aov(rep~treat+batch+Error(batch),chemproc))
anova(lm(rep~batch+treat,chemproc))  #treatment effect adjusted for the blocking factor

# batch effect adjusted for treatment
summary(aov(rep~treat+batch+Error(treat),chemproc))

#Tukey pairwise differences
chemproc.lm <- lm(rep~batch+treat,chemproc)
treat.coef <- chemproc.lm$coef[5:7]
# effect for catalyst 4 (baseline) is missing, so we add it 
treat.coef <- c(0,treat.coef)
pairwise.diff <- outer(treat.coef,treat.coef,"-")

summary(chemproc.lm)
crit.val <- qtukey(0.95,4,5)
ic.width <- crit.val*0.6982/sqrt(2)
xx <- pairwise.diff[lower.tri(pairwise.diff)] 
plot(xx,1:6,xlab="Pairwise Difference (95% CI)",ylab="",xlim=c(-5,5),pch=19,cex=1.2,axes=F) 
axis(1,seq(-5,5)) 
mtext(c("4-1","4-2","4-3","1-2","1-3","2-3"),side=2,at=1:6,line=2,las=2) 
segments(xx-ic.width,1:6,xx+ic.width,1:6,lwd=2) 
abline(v=0,lty=2,col="lightgray")

#Does this BIB perform better than a complete randomized design (without blocking)?
# relative efficiency sigma^2(CRD)/sigma^2 (RCBD)

chemproc.lm.crd <- lm(rep~treat,chemproc) 
(summary(chemproc.lm.crd)$sig/summary(chemproc.lm)$sig)^2
#Thus CRD would require 13% more bservations to obtain the same level of precision as the BIB

#interbloc variation
require(lattice) 
xyplot(rep~treat|batch,chemproc,
aspect="xy",xlab="Catalyst",ylab="Response", panel=function(x,y) {
panel.xyplot(x,y)
panel.lmline(x,y) })

```

```{r rabbit}
library(faraway)
data(rabbit)

summary(aov(gain~treat+block+Error(block),rabbit))
anova(lm(gain~block+treat,rabbit))

g<- lm(gain~block+treat,rabbit)
g1<-lm(gain~treat, rabbit)

releff<- (summary(g1)$sig/summary(g)$sig)^2



```